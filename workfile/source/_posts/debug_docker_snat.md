---
title: 记一次艰难的debug(这个题目*必须*改)
date: 2021-03-30 15:24:14
top: false
cover: false
toc: true
mathjax: true
tags:
- 网络
categories:
- 网络
---


### 现象描述

### 调查经历

### 解决方案
最后的解决方案是从别人的博客上看到的。

### 涉及到的原理，知识点，工具，命令。

### 反思，哪些弯路是可以避免的？为什么没有最开始就走最正确的路，在当时的知识储备下，有哪些可以避免的，新增的知识对以后有什么帮助？

### 怎样才是一次优秀的debug？瞅瞅人家是怎么debug的？理论上，任何事情都应该可以被找出原因，计算机世界比物理世界要简单地多，linux世界更是万物皆可触及，有无法解决的问题，但不应该没有找不到原因的问题。
https://blog.csdn.net/M2l0ZgSsVc7r69eFdTj/article/details/81380446
iptables -t nat -A POSTROUTING -o xxxx -j MASQUERADE --random-full

### linux snat设计为什么是那样的，conntrack真的只能那样设计吗？加锁不可以吗？
conntrack是一个表，用来记录在postrouting之后，snat替换的记录。当有Docker或者k8s的时候，必须打开snat，此时的执行过程如下：
当在TCP连接上做SNAT的时候，NAT模块会做以下尝试：
1. 如果包的源地址是在目标NAT池中，且{IP, 端口，协议}三元组是可用的，返回（包没有改变）。
2. 找到池中最少使用的IP，用之来替换包中的源IP。
3. 检查端口是否在允许的范围（默认1024-64512），并且带这个端口的三元组是否可用。如果可用则返回（源IP已经改变，端口未改变）。
（注意：SNAT的端口范围不受内核参数net.ipv4.ip\_local\_port\_range的影响。）
4. 端口不可用，内核通过通过调用 nf\_nat\_l4proto\_unique\_tuple()请求TCP层找到一个未使用的端口来做SNAT。
当主机上只运行着一个容器，NAT模块最可能在第三步返回。容器内部进程使用到的本地端口会被保留并用以对外的连接。当在Docker主机上运行多个容器时，
很可能一个连接的源端口已经被另一个容器的连接使用。在那种情况下，通过nf\_nat\_l4proto\_unique\_tuple()调用来找到另一个可用的端口进行NAT操作。
默认的端口分配做以下的事：
1. 从一个初始位置开始搜索并复制最近一次分配的端口。
2. 递增1。
3. 调用nf\_nat\_used\_tuple()检查端口是否已被使用。如果已被使用，重复上一步。
4. 用刚分配的端口更新最近一次分配的端口并返回。
由于端口分配和把连接插入conntrack表之间有延时，因此当nf\_nat\_used\_tuple()被并行调用时，对同一个端口的
nf\_nat\_used\_tuple()多次调用可能均回真——当端口分配以相同的初始值开始时，这种现象尤为明显。在我们的测试中，大多数端口分配冲突来自于时间间隔在0~2us内初始化的连接。

好了，了解了这个过程，我们来看一看这个思路有没有什么问题，当进行snat的时候，需要去检查端口是否是有效的，这个时候除了检查范围还要检查conntrack表中已经存放的记录，
如果这个时候有两个五元组相同的连接同时检查conntrack同时发现，conntrack是没有问题的，然后就同时分配了端口，之后等到插入conntrack的时候就会发现，重了，然后就丢了一个。
那么有什么方式可以解决这个问题，或者说这个问题的原因是在哪呢？查询，分配端口和插入conntrack表不是原子性的，但是显然如果这个是原子性的会降低性能，看起来linux想用全随机
缓解这个问题。  

*是不是可以思考一下锁的问题呢？trade off?*


